{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756d5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1963998f",
   "metadata": {},
   "source": [
    "## 1. From the given Car details dataset, compute the average weight of American cars for each make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6ec468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc=SparkContext(\"local[*]\",\"Cars-Case study\")\n",
    "\n",
    "path='C:/Users/91784/Downloads/pyspark-master (1)/pyspark-master/data_git/cars.tsv'\n",
    "\n",
    "def seqfn(z,v):\n",
    "    return (z[0]+v,z[1]+1)\n",
    "\n",
    "def combfn(a,b):\n",
    "    return(a[0]+b[0],a[1]+b[1])\n",
    "\n",
    "rdd_out=sc.textFile(path, 4) \\\n",
    "            .map(lambda s : s.split(\"\\t\")) \\\n",
    "            .filter(lambda x:x[-1]==\"American\") \\\n",
    "            .map(lambda l: (l[0],l[6])) \\\n",
    "            .mapValues(int) \\\n",
    "            .aggregateByKey((0,0),seqfn, combfn) \\\n",
    "            .mapValues(lambda x: x[0]/x[1]) \\\n",
    "            .coalesce(1)\n",
    "\n",
    "rdd_out.collect()\n",
    "\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25f544a",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efca025",
   "metadata": {},
   "source": [
    "## 2. Compute the total SUM,Avg, Max, Count of the salevalue for each customer for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1c875d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark1 = SparkSession.builder.appName('Retail').getOrCreate()\n",
    "df1=spark1.read.csv('data/Online Retail.csv', header=True, inferSchema=True)\n",
    "df1.show(2)\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "607dfa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Filter all the customers with null value\n",
    "\n",
    "df1.createOrReplaceTempView(\"DATA\")\n",
    "\n",
    "df2=spark1.sql(\"SELECT * FROM DATA where CustomerID IS NOT NULL\")\n",
    "# df_retail.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b36230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b. SaleValue is derived as UnitPrice*Quantity\n",
    "df2=df2.withColumn('SaleValue', round(df2.Quantity * df2.UnitPrice,2))\n",
    "# df_retail.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e812c68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------+----------+--------------+---------+-------------------+------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|UnitPrice|CustomerID|       Country|SaleValue|        InvoiceDate|InvoiceMonth|\n",
      "+---------+---------+--------------------+--------+---------+----------+--------------+---------+-------------------+------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|     2.55|     17850|United Kingdom|     15.3|2010-12-01 08:26:00|     2010-12|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|     3.39|     17850|United Kingdom|    20.34|2010-12-01 08:26:00|     2010-12|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|     2.75|     17850|United Kingdom|     22.0|2010-12-01 08:26:00|     2010-12|\n",
      "+---------+---------+--------------------+--------+---------+----------+--------------+---------+-------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- SaleValue: double (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- InvoiceMonth: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#c.Create the month as an additional derived column from InvoiceDAte in YYYY-MM format(ex-2022-01)\n",
    "\n",
    "df2=df2.select('InvoiceNo','StockCode','Description','Quantity','UnitPrice','CustomerID','Country','SaleValue',\n",
    "    to_timestamp(f.col('InvoiceDate'), 'M/d/y H:m').alias('InvoiceDate')\n",
    ")\n",
    "\n",
    "df2=df2.withColumn(\"InvoiceMonth\", f.from_unixtime(f.unix_timestamp(df2.InvoiceDate), \"yyyy-MM\"))\n",
    "df2.show(3)\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbbfff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-------+------+------+-----+\n",
      "|CustomerID|InvoiceMonth|    sum|   avg|   max|count|\n",
      "+----------+------------+-------+------+------+-----+\n",
      "|     15291|     2010-12|  648.9|108.15| 166.8|    6|\n",
      "|     12763|     2010-12| 320.08| 20.01|  60.0|   16|\n",
      "|     14825|     2010-12| 396.43| 22.02|  85.0|   18|\n",
      "|     14355|     2010-12|  174.4| 15.85|  25.5|   11|\n",
      "|     17404|     2010-12| 2646.3| 98.01|1188.0|   27|\n",
      "|     17343|     2010-12| 193.64| 11.39|  35.7|   17|\n",
      "|     14978|     2011-01| 689.54|  9.32|  25.5|   74|\n",
      "|     14176|     2011-01|  121.2|  30.3|  35.4|    4|\n",
      "|     17511|     2010-12|6634.76| 65.05| 232.0|  102|\n",
      "|     17567|     2010-12| 517.95| 19.18|  39.6|   27|\n",
      "|     13030|     2010-12| 427.74|  7.13| 44.85|   60|\n",
      "|     13802|     2010-12|-117.45|-58.73| -7.95|    2|\n",
      "|     12682|     2011-01| 835.11| 20.88|  72.0|   40|\n",
      "|     12647|     2010-12| 1140.7| 21.52|  90.0|   53|\n",
      "|     15021|     2010-12| 189.64|  3.33|  23.6|   57|\n",
      "|     14176|     2010-12| 156.65| 15.66| 22.95|   10|\n",
      "|     17865|     2010-12|1079.83| 25.71| 175.2|   42|\n",
      "|     13104|     2010-12| 101.76|101.76|101.76|    1|\n",
      "|     16725|     2011-01|  228.7|  6.73|  19.9|   34|\n",
      "|     15601|     2011-01|1433.83|  17.7|  71.4|   81|\n",
      "+----------+------------+-------+------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#d. Shown below is a sample of the output\n",
    "df2.groupBy(\"CustomerID\",\"InvoiceMonth\").agg(round(sum(\"SaleValue\"),2).alias(\"sum\"), \\\n",
    "         round(avg(\"SaleValue\"),2).alias(\"avg\"), \\\n",
    "         max(\"SaleValue\").alias(\"max\"), \\\n",
    "         count(\"SaleValue\").alias(\"count\") \\\n",
    "     ) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fdd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.groupBy(\"CustomerID\",\"InvoiceMonth\").agg(round(sum(\"SaleValue\"),2).alias(\"sum\"), \\\n",
    "#          round(avg(\"SaleValue\"),2).alias(\"avg\"), \\\n",
    "#          max(\"SaleValue\").alias(\"max\"), \\\n",
    "#          count(\"SaleValue\").alias(\"count\") \\\n",
    "#      ) \\\n",
    "#     .show()\n",
    "\n",
    "\n",
    "\n",
    "# spark1.sql(\"select sum(SaleValue) as Invoicesum, avg(SaleValue) as Invoinceavg, max(SaleValue) as InvoiceMax, count(SaleValue) as InvoiceCount from DATA \" +\n",
    "#           \"group by CustomerID,InvoiceMonth \").show()\n",
    "\n",
    "# spark1.sql(\"select sum(SaleValue) as Invoicesum from DATA\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e65a1",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21adea51",
   "metadata": {},
   "source": [
    "## 3. Find out the top 10 customers with highest salevalue in the year 2011. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b0d9fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=spark1.read.csv('data/Online Retail.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8926e84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+-----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|UnitPrice|CustomerID|       Country|        InvoiceDate|InvoiceYear|\n",
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+-----------+\n",
      "|   539993|    22386|JUMBO BAG PINK PO...|      10|     1.95|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    21499|  BLUE POLKADOT WRAP|      25|     0.42|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    21498| RED RETROSPOT WRAP |      25|     0.42|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- InvoiceYear: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a. Create InvoiceYear as a derived column from Invoice date\n",
    "\n",
    "df4=df3.select('InvoiceNo','StockCode','Description','Quantity','UnitPrice','CustomerID','Country',\n",
    "    to_timestamp(f.col('InvoiceDate'), 'M/d/y H:m').alias('InvoiceDate')\n",
    ")\n",
    "df4=df4.withColumn(\"InvoiceYear\", f.from_unixtime(f.unix_timestamp(df4.InvoiceDate), \"yyyy\"))\n",
    "df4=df4.filter('InvoiceYear == 2011')\n",
    "df4.show(3)\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e93eb4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+-----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|UnitPrice|CustomerID|       Country|        InvoiceDate|InvoiceYear|\n",
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+-----------+\n",
      "|   539993|    22386|JUMBO BAG PINK PO...|      10|     1.95|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    21499|  BLUE POLKADOT WRAP|      25|     0.42|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    21498| RED RETROSPOT WRAP |      25|     0.42|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    22379|RECYCLING BAG RET...|       5|      2.1|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    20718|RED RETROSPOT SHO...|      10|     1.25|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|   85099B|JUMBO BAG RED RET...|      10|     1.95|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    20682|RED RETROSPOT CHI...|       6|     3.25|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    22961|JAM MAKING SET PR...|      12|     1.45|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    22667|RECIPE BOX RETROS...|       6|     2.95|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    22898|CHILDRENS APRON A...|       8|     1.95|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    22896|PEG BAG APPLES DE...|       6|     2.55|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    22303|COFFEE MUG APPLES...|       6|     2.55|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    22302|COFFEE MUG PEARS ...|       6|     2.55|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|   85123A|WHITE HANGING HEA...|      12|     2.95|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    22808|SET OF 6 T-LIGHTS...|      12|     2.95|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    22458|CAST IRON HOOK GA...|       8|     2.55|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   539993|    22862|LOVE HEART NAPKIN...|       4|     4.25|     13313|United Kingdom|2011-01-04 10:00:00|       2011|\n",
      "|   540001|    21733|RED HANGING HEART...|      32|     2.55|     18097|United Kingdom|2011-01-04 10:22:00|       2011|\n",
      "|   540001|    22062|CERAMIC BOWL WITH...|      24|     2.95|     18097|United Kingdom|2011-01-04 10:22:00|       2011|\n",
      "|   540001|    22060|LARGE CAKE STAND ...|       6|     9.95|     18097|United Kingdom|2011-01-04 10:22:00|       2011|\n",
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# b. Filter all the customers with null value\n",
    "df4=df4.filter(\"CustomerID is not NULL\")\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "344ef76f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+-----------+---------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|UnitPrice|CustomerID|       Country|        InvoiceDate|InvoiceYear|SaleValue|\n",
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+-----------+---------+\n",
      "|   539993|    22386|JUMBO BAG PINK PO...|      10|     1.95|     13313|United Kingdom|2011-01-04 10:00:00|       2011|     19.5|\n",
      "|   539993|    21499|  BLUE POLKADOT WRAP|      25|     0.42|     13313|United Kingdom|2011-01-04 10:00:00|       2011|     10.5|\n",
      "|   539993|    21498| RED RETROSPOT WRAP |      25|     0.42|     13313|United Kingdom|2011-01-04 10:00:00|       2011|     10.5|\n",
      "+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+-----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#c. SaleValue is derived as UnitPrice*Quantity\n",
    "df4=df4.withColumn('SaleValue', round(abs(df4.Quantity * df4.UnitPrice),2))\n",
    "df4.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "92f6dd2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+\n",
      "|CustomerID|TotalSaleValue|NumberofOrders|\n",
      "+----------+--------------+--------------+\n",
      "|     16446|      336942.1|             4|\n",
      "|     14646|     272331.14|          2015|\n",
      "|     18102|      235041.5|           415|\n",
      "|     17450|     199590.57|           348|\n",
      "|     12346|      154367.2|             2|\n",
      "|     14911|     146358.75|          5585|\n",
      "|     12415|     126103.61|           778|\n",
      "|     14156|     121045.42|          1415|\n",
      "|     16029|      97944.55|           242|\n",
      "|     17511|      87211.98|           974|\n",
      "+----------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#d.Arrange the data in DESC order of SaleValue\n",
    "#e.Fetch the following data: CustomerId, TotalSaleValue, InvoiceYear,NumberofOrders\n",
    "\n",
    "df5=df4.groupby('CustomerID').agg(round(sum(\"SaleValue\"),2).alias(\"TotalSaleValue\"), \\\n",
    "                                              count(\"CustomerID\").alias(\"NumberofOrders\")).sort(f.desc(\"TotalSaleValue\"))\n",
    "\n",
    "\n",
    "df5.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc715d10",
   "metadata": {},
   "source": [
    "## 4. Create a streaming file format conversion pipeline using Filestreams to convert CSV files into PArquet files in real time.\n",
    "#Streaming source: CSV(file source), Sink: Parquet(File sink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72647e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"File Streaming\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "path = \"C:/Users/91784/Spark/stream/source_csv_files/csv_files\"\n",
    "\n",
    "    mySchema = StructType([\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"age\", IntegerType(), True),\n",
    "\n",
    "    df = spark.readStream.csv(path, header=True, schema=mySchema)\n",
    "\n",
    "    query = df \\\n",
    "        .writeStream \\\n",
    "        .outputMode('append') \\\n",
    "        .trigger(processingTime='1 seconds')\\\n",
    "        .format('parquet') \\\n",
    "        .option(\"path\", \"C:/Users/91784/Spark/stream/Output/parquet_files\") \\\n",
    "        .start()\n",
    "\n",
    "query.awaitTermination()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ca86f",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f3c1831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, concat\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Rate Streaming\")\\\n",
    "        .getOrCreate()\n",
    "        \n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")  \n",
    "    spark.conf.set(\"spark.sql.shuffle.partitions\", \"1\")\n",
    "    spark.conf.set(\"spark.sql.streaming.checkpointLocation\", \"/C:/Users/Spark/stream/checkpoint/file_sink\");\n",
    "       \n",
    "    df = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 5).load()\n",
    "    \n",
    "    \n",
    "    resultDF = df.withColumn(\"value\", concat(lit(\"Message: \"), col(\"value\"))) \\\n",
    "                 .selectExpr(\"CAST(timestamp AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "                 .withColumnRenamed(\"timestamp\", \"ts\")\\\n",
    "                 .withColumnRenamed(\"value\", \"message\")   \n",
    "    \n",
    "    def process_data(df, epoch_id):\n",
    "        \n",
    "        # write to mysql\n",
    "        df.write.format(\"jdbc\") \\\n",
    "            .option(\"url\", \"jdbc:mysql://localhost/sparkdb?autoReConnect=true&useSSL=false\") \\\n",
    "            .option(\"driver\", \"com.mysql.jdbc.Driver\") \\\n",
    "            .option(\"dbtable\", \"rate_stream_1\")  \\\n",
    "            .option(\"user\", \"root\") \\\n",
    "            .option(\"password@123\", \"Mari\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()            \n",
    "    \n",
    "        pass\n",
    "    \n",
    "    query = resultDF.writeStream.foreachBatch(process_data).start()\n",
    "    query.awaitTermination()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bf004761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "45fb5735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8af521f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570ef53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e53279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b819c70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd94122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94fc34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
